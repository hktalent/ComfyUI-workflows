{"last_node_id":225,"last_link_id":408,"nodes":[{"id":136,"type":"Reroute","pos":[1590,-450],"size":[75,26],"flags":{},"order":53,"mode":0,"inputs":[{"name":"","type":"*","link":404}],"outputs":[{"name":"VAE","type":"VAE","links":[326],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":176,"type":"Reroute","pos":[4690,-160],"size":[90.4,26],"flags":{},"order":49,"mode":0,"inputs":[{"name":"","type":"*","link":347}],"outputs":[{"name":"LATENT","type":"LATENT","links":[367],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":152,"type":"Reroute","pos":[3170,-160],"size":[90.4,26],"flags":{},"order":43,"mode":0,"inputs":[{"name":"","type":"*","link":346}],"outputs":[{"name":"LATENT","type":"LATENT","links":[347],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":181,"type":"Reroute","pos":[1570,290],"size":[75,26],"flags":{},"order":0,"mode":0,"inputs":[{"name":"","type":"*","link":null,"slot_index":0}],"outputs":[{"name":"*","type":"*","links":[352],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":179,"type":"Reroute","pos":[1560,620],"size":[75,26],"flags":{},"order":1,"mode":0,"inputs":[{"name":"","type":"*","link":null,"slot_index":0}],"outputs":[{"name":"*","type":"*","links":[351],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":166,"type":"Reroute","pos":[1570,1300],"size":[75,26],"flags":{},"order":47,"mode":0,"inputs":[{"name":"","type":"*","link":358,"slot_index":0}],"outputs":[{"name":"CLIP","type":"CLIP","links":[330,334],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":170,"type":"Reroute","pos":[2110,1250],"size":[75,26],"flags":{},"order":51,"mode":0,"inputs":[{"name":"","type":"*","link":330}],"outputs":[{"name":"CLIP","type":"CLIP","links":[331],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":92,"type":"PreviewImage","pos":[4800,530],"size":{"0":210,"1":246},"flags":{},"order":44,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":341}],"properties":{"Node name for S&R":"PreviewImage"}},{"id":103,"type":"PreviewImage","pos":[5430,540],"size":{"0":210,"1":246},"flags":{},"order":45,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":344}],"properties":{"Node name for S&R":"PreviewImage"}},{"id":188,"type":"Reroute","pos":[803,1032],"size":[75,26],"flags":{},"order":41,"mode":0,"inputs":[{"name":"","type":"*","link":405,"slot_index":0}],"outputs":[{"name":"CLIP","type":"CLIP","links":[358],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":6,"type":"CLIPTextEncode","pos":[2418,1432],"size":{"0":401.5390930175781,"1":199.9014129638672},"flags":{},"order":56,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":333}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[133],"shape":3,"slot_index":0}],"title":"Negative Prompt","properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["ugly, deformed, bad lighting, blurry, text, watermark, extra hands, bad quality, deformed hands, deformed fingers, nostalgic, drawing, painting, bad anatomy, worst quality, blurry, blurred, normal quality, bad focus, tripod, three legs, weird legs, short legs, bag, handbag, 3 hands, 4 hands, three hands\n\n(embedding:BadDream:1) boy, man, male,\n(embedding:ng_deepnegative_v1_75t:1), \n(embedding:epiCNegative:1), \n(embedding:bad-picture-chill-75v:1), \n(embedding:AS-YoungV2-neg:1), \n(embedding:ERA09NEGV2:1)"],"color":"#232","bgcolor":"#353"},{"id":94,"type":"ADE_AnimateDiffUniformContextOptions","pos":[1392,1043],"size":{"0":315,"1":154},"flags":{"collapsed":false},"order":2,"mode":0,"outputs":[{"name":"CONTEXT_OPTIONS","type":"CONTEXT_OPTIONS","links":[206],"shape":3}],"properties":{"Node name for S&R":"ADE_AnimateDiffUniformContextOptions"},"widgets_values":[16,1,4,"uniform",true]},{"id":3,"type":"CLIPTextEncode","pos":[2421,1252],"size":{"0":392.5286865234375,"1":131.9727783203125},"flags":{},"order":55,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":331}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[132],"shape":3,"slot_index":0}],"title":"Positive Prompt","properties":{"Node name for S&R":"CLIPTextEncode"},"widgets_values":["(masterpiece, top quality, best quality, official art, beautiful and aesthetic:1.2), girl, female, (1girl), red jacket, jeans, heels"],"color":"#232","bgcolor":"#353"},{"id":169,"type":"Reroute","pos":[3260,250],"size":[82,26],"flags":{},"order":50,"mode":0,"inputs":[{"name":"","type":"*","link":328}],"outputs":[{"name":"MODEL","type":"MODEL","links":[399],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":217,"type":"Reroute","pos":[4066,249],"size":[82,26],"flags":{},"order":54,"mode":0,"inputs":[{"name":"","type":"*","link":399}],"outputs":[{"name":"MODEL","type":"MODEL","links":[398],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":165,"type":"Reroute","pos":[798,980],"size":[82,26],"flags":{},"order":40,"mode":0,"inputs":[{"name":"","type":"*","link":401,"slot_index":0}],"outputs":[{"name":"MODEL","type":"MODEL","links":[322],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":180,"type":"Reroute","pos":[1778,567],"size":[75,26],"flags":{},"order":33,"mode":0,"inputs":[{"name":"","type":"*","link":351,"slot_index":0}],"outputs":[{"name":"*","type":"*","links":null}],"properties":{"showOutputText":true,"horizontal":false}},{"id":2,"type":"VAELoader","pos":[728.7334716796875,-368],"size":{"0":385.8948669433594,"1":58},"flags":{},"order":3,"mode":0,"outputs":[{"name":"VAE","type":"VAE","links":[],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAELoader"},"widgets_values":["vae-ft-mse-840000-ema-pruned.ckpt"]},{"id":171,"type":"Reroute","pos":[2111,1431],"size":[75,26],"flags":{},"order":52,"mode":0,"inputs":[{"name":"","type":"*","link":334}],"outputs":[{"name":"CLIP","type":"CLIP","links":[333],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":208,"type":"Note","pos":[627,51],"size":{"0":557.23828125,"1":363.5209045410156},"flags":{},"order":4,"mode":0,"title":"2) Instructions","properties":{"text":""},"widgets_values":["HOW TO USE : \n\n1) Choose Model checkpoint you want to use\n2) Enter Width and Height of your Output Image \n3) Enter Prompts \n4) Select Batch Range (Number of images you want to render in one Queue)\n5) After every queue increase the skip frames to the Total number of images rendered already.\n(Skip Step 5 if you have batch range set equal to your source images)\n6) Paste the Passes Directories in ControlNets Loaders\n7) Start The Render Queue.\n8) Grab some snacks because it going to take long, go watch a movie on Netflix.\n(Step 8 is mandatory) \n9) After all the images are rendered, organize them in a separate folder.\n10) Ready for Adetailer Face Fix, Follow Instruction down below.\n(Skip Step 10 if faces are good or you are not using any humans) "],"color":"#2a363b","bgcolor":"#3f5159","shape":4},{"id":207,"type":"Note","pos":[628,472],"size":{"0":561.3285522460938,"1":326.8934020996094},"flags":{},"order":5,"mode":0,"title":"3) Adetailer Face Fix in Automatic 1111","properties":{"text":""},"widgets_values":["After Organizing the images in one Folder, Copy this Directory path.\n\n1) Go to Img2Img tab, drag and drop 1 image from the directory which has the full face visible, \n2) Make the resolution same as image, use the auto detect button\n3) Go the Adetailer tab and enable Adetailer, also enable skip img2img (Update extension if you don't have this button, it's new, else set the main img2img denoising to 0)\n4) Enter Prompts in the Adetailer and test till you like the face, use the same model as you used in AnimateDiff, You can try different for creative results. \n5) Once you like the face, then Paste the Directory in the Batch Tab.\n6) Generate all frames. Check the first few output frames for consistency. Interrupt the queue and retry if disproportionate faces.    \n7) Try lowering the inpaint denoise strength to 0.2-0.35 in adetailer for consistency if the faces are misplaced or looking weird.Â \n10) Sequence in After Effects or Davinci with Audio and Post processing when all frames rendered properly.\n\n \n\nDone! Enjoy :D\n\nFAQ : \nQ) Why A1111 Adetailer and not Comfyui face Detailer ? \nBecause in A1111 you can test faster :)\n\nQ) Can you fix hands in adetailer ? \nYes, enable the 2nd tab in adetailer with hands option but they will flicker more.\n\nQ) I am sigma male, I won't use A1111 as I'm loyal to Comfy!\nThat's your personal problem , you can use this technique: https://www.youtube.com/watch?v=z4JzuuFyr1Y&t=1s\n\nBatch images in face detailer won't work read this to fix the pipeline: \nhttps://www.reddit.com/r/StableDiffusion/comments/172u3o1/animatediff_facedetailer_or_batchimage/\n\n"],"color":"#2a363b","bgcolor":"#3f5159","shape":4},{"id":182,"type":"Reroute","pos":[1778,381],"size":[75,26],"flags":{},"order":32,"mode":0,"inputs":[{"name":"","type":"*","link":352,"slot_index":0}],"outputs":[{"name":"*","type":"*","links":null}],"properties":{"showOutputText":true,"horizontal":false}},{"id":105,"type":"PrimitiveNode","pos":[1732,36],"size":{"0":210,"1":82},"flags":{"collapsed":false},"order":6,"mode":0,"outputs":[{"name":"INT","type":"INT","links":[300],"slot_index":0,"widget":{"name":"height"}}],"title":"Height","properties":{},"widgets_values":[960,"fixed"],"color":"#232","bgcolor":"#353"},{"id":104,"type":"PrimitiveNode","pos":[1731,-94],"size":{"0":210,"1":82},"flags":{"collapsed":false},"order":7,"mode":0,"outputs":[{"name":"INT","type":"INT","links":[350],"slot_index":0,"widget":{"name":"width"}}],"title":"Width","properties":{},"widgets_values":[544,"fixed"],"color":"#232","bgcolor":"#353"},{"id":151,"type":"EmptyLatentImage","pos":[2189,17],"size":{"0":315,"1":106},"flags":{},"order":37,"mode":0,"inputs":[{"name":"width","type":"INT","link":350,"widget":{"name":"width"}},{"name":"height","type":"INT","link":300,"widget":{"name":"height"}},{"name":"batch_size","type":"INT","link":305,"widget":{"name":"batch_size"},"slot_index":2}],"outputs":[{"name":"LATENT","type":"LATENT","links":[346],"shape":3,"slot_index":0}],"title":"Empty Latent Images","properties":{"Node name for S&R":"EmptyLatentImage"},"widgets_values":[544,960,10]},{"id":113,"type":"Reroute","pos":[4052,-264],"size":[75,26],"flags":{},"order":57,"mode":0,"inputs":[{"name":"","type":"*","link":326}],"outputs":[{"name":"","type":"VAE","links":[236],"slot_index":0}],"properties":{"showOutputText":false,"horizontal":false}},{"id":223,"type":"Reroute","pos":[-768,1030],"size":[75,26],"flags":{},"order":35,"mode":0,"inputs":[{"name":"","type":"*","link":406}],"outputs":[{"name":"CLIP","type":"CLIP","links":[405]}],"properties":{"showOutputText":true,"horizontal":false}},{"id":213,"type":"Reroute","pos":[109,814],"size":[75,26],"flags":{},"order":42,"mode":0,"inputs":[{"name":"","type":"*","link":407}],"outputs":[{"name":"VAE","type":"VAE","links":[383],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":224,"type":"Reroute","pos":[-805,815],"size":[75,26],"flags":{},"order":36,"mode":0,"inputs":[{"name":"","type":"*","link":408}],"outputs":[{"name":"VAE","type":"VAE","links":[407]}],"properties":{"showOutputText":true,"horizontal":false}},{"id":219,"type":"DynamicThresholdingFull","pos":[259,933],"size":{"0":315,"1":298},"flags":{},"order":34,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":403}],"outputs":[{"name":"MODEL","type":"MODEL","links":[401],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"DynamicThresholdingFull"},"widgets_values":[7,1,"Half Cosine Up",5,"Half Cosine Up",5,1,"enable","MEAN","AD",1]},{"id":10,"type":"VAEDecode","pos":[7329,121],"size":{"0":210,"1":46},"flags":{},"order":61,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":9},{"name":"vae","type":"VAE","link":236}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[289],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":72,"type":"ControlNetApplyAdvanced","pos":[4299,1309],"size":{"0":315,"1":166},"flags":{},"order":58,"mode":0,"inputs":[{"name":"positive","type":"CONDITIONING","link":132},{"name":"negative","type":"CONDITIONING","link":133},{"name":"control_net","type":"CONTROL_NET","link":118},{"name":"image","type":"IMAGE","link":339}],"outputs":[{"name":"positive","type":"CONDITIONING","links":[218],"shape":3,"slot_index":0},{"name":"negative","type":"CONDITIONING","links":[219],"shape":3,"slot_index":1}],"properties":{"Node name for S&R":"ControlNetApplyAdvanced"},"widgets_values":[0.7000000000000001,0,0.8],"color":"#232","bgcolor":"#353"},{"id":99,"type":"ControlNetApplyAdvanced","pos":[5010,1310],"size":{"0":315,"1":166},"flags":{},"order":59,"mode":0,"inputs":[{"name":"positive","type":"CONDITIONING","link":218},{"name":"negative","type":"CONDITIONING","link":219},{"name":"control_net","type":"CONTROL_NET","link":209},{"name":"image","type":"IMAGE","link":345}],"outputs":[{"name":"positive","type":"CONDITIONING","links":[221],"shape":3,"slot_index":0},{"name":"negative","type":"CONDITIONING","links":[220],"shape":3,"slot_index":1}],"properties":{"Node name for S&R":"ControlNetApplyAdvanced"},"widgets_values":[0.77,0,0.8],"color":"#232","bgcolor":"#353"},{"id":7,"type":"KSampler","pos":[6430,250],"size":{"0":315,"1":446},"flags":{"pinned":false},"order":60,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":398},{"name":"positive","type":"CONDITIONING","link":221},{"name":"negative","type":"CONDITIONING","link":220},{"name":"latent_image","type":"LATENT","link":367},{"name":"seed","type":"INT","link":6,"widget":{"name":"seed"}}],"outputs":[{"name":"LATENT","type":"LATENT","links":[9],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[606307432098863,"fixed",22,7,"dpmpp_2m","karras",1],"color":"#232","bgcolor":"#353"},{"id":184,"type":"Reroute","pos":[1041,-541],"size":[75,26],"flags":{},"order":48,"mode":0,"inputs":[{"name":"","type":"*","link":383}],"outputs":[{"name":"VAE","type":"VAE","links":[404],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":1,"type":"CheckpointLoaderSimpleWithNoiseSelect","pos":[-1241,933],"size":{"0":319.20001220703125,"1":122},"flags":{},"order":8,"mode":0,"outputs":[{"name":"MODEL","type":"MODEL","links":[403],"shape":3,"slot_index":0},{"name":"CLIP","type":"CLIP","links":[406],"shape":3,"slot_index":1},{"name":"VAE","type":"VAE","links":[408],"shape":3,"slot_index":2}],"title":"Load Checkpoint","properties":{"Node name for S&R":"CheckpointLoaderSimpleWithNoiseSelect"},"widgets_values":["18) meinamix_meinaV11.safetensors","sqrt_linear (AnimateDiff)"],"color":"#232","bgcolor":"#353"},{"id":147,"type":"SaveImage","pos":[7694,120],"size":{"0":315,"1":270},"flags":{},"order":62,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":289}],"properties":{},"widgets_values":["Img"]},{"id":189,"type":"Note","pos":[-1246,1108],"size":{"0":326.4343566894531,"1":212.6419677734375},"flags":{},"order":9,"mode":0,"properties":{"text":""},"widgets_values":["Checkpoint - Try Different Checkpoints for creative results \n\nTo use Lora - add the Lora loader node in the middle of load checkpoint node and Dynamic thresholding node.\n\nIf your renders are glitchy or incomplete, it may be lora incompatible with AnimateDiff Loader or You have some problem in the Prompts.\n\nBeta_Scheldule: It only works with sqrt_linear(AnimateDiff)"],"color":"#432","bgcolor":"#653"},{"id":177,"type":"Note","pos":[1265,200],"size":{"0":355.5671081542969,"1":233.20599365234375},"flags":{},"order":10,"mode":0,"properties":{"text":""},"widgets_values":["Skip Frames - After Each Queue, skip the \"total\" of rendered frames. \n(Give some rest to the computer so it does not catch fire, don't be cruel)\n\nEg:\n \n1st Queue- Batch Range 60 | Skip Frames 0  | Rendered 60 \n2nd Queue- Batch Range 60 | Skip Frames 60 | Rendered 60\n3rd Queue- Batch Range 60 | Skip Frames 120 (60+60)...\nand so on... till your batch size.\n\nInput your last batch correctly. \n\nWarning: Ksampler can stuck if your input batch range is greater than the source images.\n\nEg : I have my last batch of 55 images left but I input 60 images in batch range then the ksampler got stuck. \nThen I put 55 as my batch range then it worked. Hurraah!\n\n\n\nTip: In the input box, basic Maths can be done inside comfyui only not need of calculator. \n\nEg : if I put \"200-50\" (250 minus 50) in the input, it will calculate to 150 automatically, like wise other basic Maths\n\n\n\n\n\n\n\n"],"color":"#432","bgcolor":"#653"},{"id":206,"type":"Note","pos":[2193,-221],"size":{"0":308.27618408203125,"1":185.11119079589844},"flags":{},"order":11,"mode":0,"properties":{"text":""},"widgets_values":["Empty Latent Images - It Provides empty latents for Ksampler\n\nDon't Use \"0\" in Batch Range as it also goes provides for Latent Image for ksampler else it will break."],"color":"#432","bgcolor":"#653"},{"id":183,"type":"Note","pos":[1663,-362],"size":{"0":347.39410400390625,"1":207.8466796875},"flags":{},"order":12,"mode":0,"properties":{"text":""},"widgets_values":["Use Low Resolution for Faster Render. If faces are not rendering good try to increase resolution in small amounts. \nFaces can be fixed later also, No need to Panic.\n \nCheck Preview of ControlNets if they are looking proportionate or not.\n\nTest for 10 Frames first, Set Batch range to \"10\""],"color":"#432","bgcolor":"#653"},{"id":209,"type":"Note","pos":[703,-222],"size":{"0":446.8656921386719,"1":77.2004623413086},"flags":{},"order":13,"mode":0,"title":"Optional","properties":{"text":""},"widgets_values":["If you want to use another VAE than the model's provided VAE, choose it here and connect it to the VAE reroute node in the side.\n\n "],"color":"#432","bgcolor":"#653"},{"id":187,"type":"Note","pos":[2287,993],"size":{"0":474.1103820800781,"1":160.2073974609375},"flags":{},"order":14,"mode":0,"properties":{"text":""},"widgets_values":["AnimateDiff Loader - The Model you use will affect the animation of overall image, You can use any.\n\nMotion Lora - It is optional as every image has its control net image so no need, you can test out for background elements.\n\nContext Length - Use Maximum Values upto 32 for less changes \"flickering transition\", Some models do not support \"32\" so lower it according to the model's capacity. (Lower valuer = more flicker) [16 is stable] \n\nOverlap - You can experiment with it, higher value will have smooth flicker .. Doesn't work if greater then Context length [4-6 value is good]\n\nClosed_Loop - No effects observed in this workflow.\n\nBeta_Scheldule: It only works with sqrt_linear(AnimateDiff)"],"color":"#432","bgcolor":"#653"},{"id":201,"type":"Note","pos":[2416,1691],"size":{"0":413.98907470703125,"1":256.0702819824219},"flags":{},"order":15,"mode":0,"properties":{"text":""},"widgets_values":["*Positive Prompt: Write as usual, specify minute details, the elements are usually changed during the render, also you can try to use same keywords multiple times but same meaning ( Eg: blue jeans, blue color jeans, jeans of blue color) to reduce major changes. \n\nUsing the word multiple times increase it's strength.\nAvoid writing multiple color words. A prompt which has \"black\" keyword written x3 will darken the image x3\n\n\nIf you weight the keywords like \"(this:1.9), it may produce glitchy result. Avoid high weights.\n\n*Negative Prompt: Write as usual, Sometimes Negative prompts causes noise in images, try reducing the use of embeddings if you encounter them. \n\n"],"color":"#432","bgcolor":"#653"},{"id":204,"type":"Note","pos":[4325,1530],"size":{"0":268.38897705078125,"1":93.16358947753906},"flags":{},"order":16,"mode":0,"title":"Softedge, Canny, Lineart","properties":{"text":""},"widgets_values":["Stronger Strength and End Percent results in floating artifacts and Alien objects in Softedge, Canny, or lineArt Models\n\nYou can experiment with depth also"],"color":"#432","bgcolor":"#653"},{"id":199,"type":"Note","pos":[5052,559],"size":{"0":301.9181213378906,"1":113.35253143310547},"flags":{},"order":17,"mode":0,"title":"Laggy Scroll","properties":{"text":""},"widgets_values":["TIP: It Will be laggy in this area because Preview Node shows a tons of images in it's full resolution, Disconnect these \"Preview Image\" nodes for smooth scrolling. "],"color":"#432","bgcolor":"#653"},{"id":194,"type":"Note","pos":[5187,1058],"size":{"0":301.9181213378906,"1":113.35253143310547},"flags":{},"order":18,"mode":0,"properties":{"text":""},"widgets_values":["Copy the Full Directory for the ControlNet 2 Images and paste above."],"color":"#432","bgcolor":"#653"},{"id":205,"type":"Note","pos":[5330,1509],"size":{"0":346.503173828125,"1":157.56500244140625},"flags":{},"order":19,"mode":0,"title":"Additional ControlNets","properties":{"text":""},"widgets_values":["You Can Add more ControlNets, just make that Pass in the ControlNet_Passes_Export.json and duplicating the directory node and using it like these previous nodes.\n\nMore control nets do not affect the time to render as they have already been rendered which makes it easy to test animations. By default 2 controlNets are enough. \n\n"],"color":"#432","bgcolor":"#653"},{"id":221,"type":"Note","pos":[5917,975],"size":{"0":431.3703918457031,"1":388.0624084472656},"flags":{},"order":20,"mode":0,"title":"TIP","properties":{"text":""},"widgets_values":["\nBUG 2: Sometimes longer Batches export incomplete or smudged images in models like ToonYou.beta6 or mistoonAnime, for that SD model use short batches, and fix the sharp transition with this tip.\n\n\n\nTip: You can render 5 previous frames before the next batch and fade the transition in post. \n\nEg: \n\nTotal Input source images = 200\n\n1st Batch of 100 = 100 frames \n2nd Batch from 95 till 200 =  5 previous frames for overlapping + 100 new frames\n\nFade the Overlapping 5 frames in post for smoother transition.  "],"color":"#432","bgcolor":"#653"},{"id":222,"type":"Note","pos":[7333,222],"size":{"0":210,"1":93.13619232177734},"flags":{},"order":21,"mode":0,"title":"Saving","properties":{"text":""},"widgets_values":["Save the Images and sequence them in post.\n\n"],"color":"#432","bgcolor":"#653"},{"id":193,"type":"Note","pos":[4013,1066],"size":{"0":301.9181213378906,"1":113.35253143310547},"flags":{},"order":22,"mode":0,"properties":{"text":""},"widgets_values":["Copy the Full Directory for the ControlNet 1 Images and paste above."],"color":"#432","bgcolor":"#653"},{"id":200,"type":"Note","pos":[5915,698],"size":{"0":434.11865234375,"1":228.54293823242188},"flags":{},"order":23,"mode":0,"title":"Seed Bug","properties":{"text":""},"widgets_values":["\nBUG: If you are rendering images in multiple batches, After each Batch the Images will change even after same seed, so it can't be helped. \n\nSOLUTION: Render it in one go or longer batches, it will take hours to render ( You can minimize this bug by specifying the minute details in prompts) or in Davinci \n\nRandomizing seed will increase this Bug Effect.\n\nYou can try changing the Model in AnimateDiff Loader Node, if it fixes or reduce this bug.\n\n\n\n"],"color":"#432","bgcolor":"#653"},{"id":70,"type":"ControlNetLoaderAdvanced","pos":[3879,1658],"size":{"0":367.79998779296875,"1":58},"flags":{"collapsed":false},"order":24,"mode":0,"inputs":[{"name":"timestep_keyframe","type":"TIMESTEP_KEYFRAME","link":null}],"outputs":[{"name":"CONTROL_NET","type":"CONTROL_NET","links":[118],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"ControlNetLoaderAdvanced"},"widgets_values":["control_v11p_sd15_softedge.pth"],"color":"#232","bgcolor":"#353"},{"id":97,"type":"ControlNetLoaderAdvanced","pos":[4604,1668],"size":{"0":367.79998779296875,"1":58},"flags":{},"order":25,"mode":0,"inputs":[{"name":"timestep_keyframe","type":"TIMESTEP_KEYFRAME","link":null}],"outputs":[{"name":"CONTROL_NET","type":"CONTROL_NET","links":[209],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"ControlNetLoaderAdvanced"},"widgets_values":["control_v11p_sd15_openpose.pth"],"color":"#232","bgcolor":"#353"},{"id":174,"type":"LoadImagesFromDirectory","pos":[4870,884],"size":{"0":315,"1":146},"flags":{},"order":39,"mode":0,"inputs":[{"name":"image_load_cap","type":"INT","link":360,"widget":{"name":"image_load_cap"},"slot_index":0},{"name":"start_index","type":"INT","link":362,"widget":{"name":"start_index"}}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[344,345],"shape":3,"slot_index":0},{"name":"MASK","type":"MASK","links":null,"shape":3},{"name":"INT","type":"INT","links":null,"shape":3}],"title":"ControlNet 2","properties":{"Node name for S&R":"LoadImagesFromDirectory"},"widgets_values":["F:\\#Projects\\1) SD Animation\\8) Collide By HellenPeng\\OpenPose",10,0],"color":"#323","bgcolor":"#535"},{"id":172,"type":"LoadImagesFromDirectory","pos":[4360,960],"size":{"0":315,"1":146},"flags":{},"order":38,"mode":0,"inputs":[{"name":"image_load_cap","type":"INT","link":359,"widget":{"name":"image_load_cap"},"slot_index":0},{"name":"start_index","type":"INT","link":361,"widget":{"name":"start_index"}}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[339,341],"shape":3,"slot_index":0},{"name":"MASK","type":"MASK","links":null,"shape":3},{"name":"INT","type":"INT","links":null,"shape":3}],"title":"ControlNet 1","properties":{"Node name for S&R":"LoadImagesFromDirectory"},"widgets_values":["F:\\#Projects\\1) SD Animation\\8) Collide By HellenPeng\\HED",10,0],"color":"#323","bgcolor":"#535"},{"id":5,"type":"PrimitiveNode","pos":[5996,538],"size":{"0":210,"1":82},"flags":{},"order":26,"mode":0,"outputs":[{"name":"INT","type":"INT","links":[6],"slot_index":0,"widget":{"name":"seed"}}],"title":"Seed","properties":{},"widgets_values":[606307432098863,"fixed"]},{"id":160,"type":"PrimitiveNode","pos":[1841,534],"size":{"0":210,"1":82},"flags":{},"order":27,"mode":0,"outputs":[{"name":"INT","type":"INT","links":[305,359,360],"slot_index":0,"widget":{"name":"batch_size"}}],"title":"Batch Range","properties":{},"widgets_values":[10,"fixed"],"color":"#232","bgcolor":"#353"},{"id":164,"type":"PrimitiveNode","pos":[1835,366],"size":{"0":210,"1":82},"flags":{},"order":28,"mode":0,"outputs":[{"name":"INT","type":"INT","links":[361,362],"slot_index":0,"widget":{"name":"start_index"}}],"title":"Skip Frames","properties":{},"widgets_values":[0,"fixed"],"color":"#232","bgcolor":"#353"},{"id":175,"type":"Note","pos":[1263,495],"size":{"0":358.7886657714844,"1":381.8414611816406},"flags":{},"order":29,"mode":0,"properties":{"text":""},"widgets_values":["Batch Range - How much images you want to render in a single queue.\n\nIt also Controls the number of empty latent images for Ksampler\n\nUse Exact Number of images you want to render.\n\nDon't Use \"0\" as it also provides for Latent Image for ksampler else it will break.\n\nTIP: Use at least 10 frames for testing else it will give you noisy image.\n\n\n----------------------Â \n\nBUG: If you are rendering images in batches because of low specs, After each Batch the Images will change even after same seed, so it can't be helped. \n\nSOLUTION: Render it in one go or longer batches, it will take hours to render, put some ice on the graphic card for faster result :D ( You can minimize this bug by specifying the minute details in prompts) or \nFix in Davinci Deflicker - Flora Light (Masking the duration only of the sudden change), \nAlso See the tip in Note Near the Ksampler node.\n\n--------------------\n\nBUG 2: I have 8GB graphics so max frames I can render in a single go is around 150 \n\nIf I go beyond that, the ksampler will show like its rendering but will not actually render.\n\nIf your GPU is not melting then your ksampler is stuck, try reducing the batch range then try melting again :)"],"color":"#432","bgcolor":"#653"},{"id":225,"type":"Note","pos":[-868,58],"size":{"0":565.9544677734375,"1":719.0118408203125},"flags":{},"order":30,"mode":0,"title":"4) Bug List","properties":{"text":""},"widgets_values":["1) Video frames are not in sequence or random. \nCause: Naming format of the input frames.\nâ Solution: Rename the frames, with bulk renamer from 1,2,3,4.....pngs to 0001,0002,0003....pngs, exporting from after effects does this renaming properly use AE while converting the video.\n\n\n2) Out of Memory error, after reaching the Ksampler node\nCause: Your PC is Running out of Vram of the Graphic Card. \nâ Solution:\nA) Just Queue Prompt again, sometimes it fixes the error, because it has already cached through the model loaders. (If you have an 8gb graphic card)  \nB) Batch Range is too high, try lowering it (150-200 in one batch should be fine)\nC) Resolution is too high, you can upscale later also... (use lower than 1000x1000)  \nD) The SD model you are using is very big in size, it takes up ram. Use different SD model. \nE) This workflow is not tested on SDXL models because of it's vram consumption, So avoid SDXLs.\n\n3) Rendered output frames are smudgy or incomplete. \nCause: Experimental Technology. Sometimes it works, sometimes don't.  \nâ Solution: \nA) Try lowering the batch size, the details get smushed along the frames. Lower batch range (20-50) has the highest details. \nB) Your Prompt has weightings like -->(this:1.7)<-- remove this weighting. \nC) Negative Embeddings sometimes messes things up. Try isolating them one by one.   \n\n  \n\n4) Ksampler is stuck, it's rendering but not progressing. \nâ Solution: \nA) If you do not hear the Phooooo... or Pheeeeee sound of the graphic card in a minute after when the green box hits the Ksampler node, that means it's stuck. You need to low down the batch range. It's too much to handle at once, so it handles none ã( â, â )ã. Lower the batch range size.\nB) You have 40 images left in the last batch but the batch range is set to 50. So 50-40 is 10. This extra 10 images can stuck the KSampler.\n\n5) I rendered out fine, but it's not looking what it should be\nâ Solution: You might have mixed the passes in the control net unit. Check if Openpose passes are going in the openposemodel model. And like wise for the softedge, canny... and others.\n\n\n6) I have the same Seed but the transition images of the batches are not same and creates a sharp change.\nâ Solution: Even after the same seed, the transition (end image of first batch and first image of 2nd batch will differ very much) which will create a sharp transition. Use this tip: You can render 5 previous frames before the next batch and fade the transition in post. \n\nEg: \n\nTotal Input source images = 200\n\n1st Batch of 100 = 100 frames \n2nd Batch from 95 till 200 =  5 previous frames for overlapping + 100 new frames\n\nFade the Overlapping 5 frames in post for smoother transition.  \n\n    \n\n\n\n\n  \n"],"color":"#323","bgcolor":"#535","shape":2},{"id":93,"type":"ADE_AnimateDiffLoaderWithContext","pos":[1850,910],"size":{"0":407.929931640625,"1":165.60914611816406},"flags":{"collapsed":false},"order":46,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":322},{"name":"context_options","type":"CONTEXT_OPTIONS","link":206,"slot_index":1},{"name":"motion_lora","type":"MOTION_LORA","link":null}],"outputs":[{"name":"MODEL","type":"MODEL","links":[328],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"ADE_AnimateDiffLoaderWithContext"},"widgets_values":["temporaldiff-v1-animatediff.safetensors","sqrt_linear (AnimateDiff)"]},{"id":190,"type":"Note","pos":[27,50],"size":{"0":565.9544677734375,"1":719.0118408203125},"flags":{},"order":31,"mode":0,"title":"1) Main Note","properties":{"text":""},"widgets_values":["1) All Green Nodes are Inputs and require your attention, Purple Nodes are Input Images Directory Nodes for controlNet passes, and are very important else this workflow won't run \n\n2) Control Net Passes are already rendered to save time, you need to have them before using this workflow, Extract them using the Provided ControlNet_Passes_Export.json file  (You can experiment with different control nets or use only one)\n\n3) If Faces are not Looking right don't panic, it's gonna happen, watch the tutorial link below which will show how to fix faces, using adetailer in A1111 (I tried comfyUI face detailer but it had no consistency) \n\n4) Use value at least \"10\" in batch range to test render out your animation before final render. Lower than 10 frames may result in noisy images.\n\n\n5) Use Link Render Mode to straight lines in ComfyUI Settings (Gear Icon in the right of the Queues Box) so the workflow doesn't look like spaghetti. \n\n\nâ FULL VIDEO TUTORIAL LINK: https://youtu.be/HbfDjAMFi6w\n\n\n\nI post my workflows, tutorials and secret techniques without any cost on my patreon, just click \"join for free\" and sign up click \"skip the payment\" and you will be part of my journey for free.\nPatreon link: patreon.com/jerrydavos\n\n\nif you want to share your artwork with me, feel free to contact me on Discord - ID: jerrydavos \nor gmail : davos.jerry+contactai@gmail.com \nI will be very happy to see your works <3 \n\n\n\n-----------------------------------------------------------------\nResources Used : \n\n1) ComfyUI Impact Pack\nhttps://github.com/ltdrdata/ComfyUI-Impact-Pack\n\n2) ComfyUI_FizzNodes \nhttps://github.com/FizzleDorf/ComfyUI_FizzNodes\n\n3) ComfyUI's ControlNet Auxiliary Preprocessors\nhttps://github.com/Fannovel16/comfyui_controlnet_aux\n\n4) ComfyUI-Advanced-ControlNet \nhttps://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet\n\n5) ComfyUI Inspire Pack\nhttps://github.com/ltdrdata/ComfyUI-Inspire-Pack\n\n6) AnimateDiff Evolved\nhttps://github.com/Kosinkadink/ComfyUI-AnimateDiff-Evolved\n\n7) ComfyUI-VideoHelperSuite\nhttps://github.com/Kosinkadink/ComfyUI-VideoHelperSuite\n\n8) Dynamic Thresholding : https://github.com/mcmonkeyprojects/sd-dynamic-thresholding\n\nSearch In ComfyUI Manager or Install Missing Node\n\n----Checkpoint----\n\nTemporaldiff-v1-animatediff\nhttps://huggingface.co/CiaraRowles/TemporalDiff/tree/main\nPut in : ComfyUI\\custom_nodes\\ComfyUI-AnimateDiff-Evolved\\models\n\n------------------------------------------------------------------\n\n*Minimum Requirement to run AnimateDiff is Nvidia RTX cards with at least 8GB.\n\nNode Workflow by\nJerry Davos\n"],"color":"#2a363b","bgcolor":"#3f5159","shape":4}],"links":[[6,5,0,7,4,"INT"],[9,7,0,10,0,"LATENT"],[118,70,0,72,2,"CONTROL_NET"],[132,3,0,72,0,"CONDITIONING"],[133,6,0,72,1,"CONDITIONING"],[206,94,0,93,1,"CONTEXT_OPTIONS"],[209,97,0,99,2,"CONTROL_NET"],[218,72,0,99,0,"CONDITIONING"],[219,72,1,99,1,"CONDITIONING"],[220,99,1,7,2,"CONDITIONING"],[221,99,0,7,1,"CONDITIONING"],[236,113,0,10,1,"VAE"],[289,10,0,147,0,"IMAGE"],[300,105,0,151,1,"INT"],[305,160,0,151,2,"INT"],[322,165,0,93,0,"MODEL"],[326,136,0,113,0,"*"],[328,93,0,169,0,"*"],[330,166,0,170,0,"*"],[331,170,0,3,0,"CLIP"],[333,171,0,6,0,"CLIP"],[334,166,0,171,0,"*"],[339,172,0,72,3,"IMAGE"],[341,172,0,92,0,"IMAGE"],[344,174,0,103,0,"IMAGE"],[345,174,0,99,3,"IMAGE"],[346,151,0,152,0,"*"],[347,152,0,176,0,"*"],[350,104,0,151,0,"INT"],[351,179,0,180,0,"*"],[352,181,0,182,0,"*"],[358,188,0,166,0,"*"],[359,160,0,172,0,"INT"],[360,160,0,174,0,"INT"],[361,164,0,172,1,"INT"],[362,164,0,174,1,"INT"],[367,176,0,7,3,"LATENT"],[383,213,0,184,0,"*"],[398,217,0,7,0,"MODEL"],[399,169,0,217,0,"*"],[401,219,0,165,0,"*"],[403,1,0,219,0,"MODEL"],[404,184,0,136,0,"*"],[405,223,0,188,0,"*"],[406,1,1,223,0,"*"],[407,224,0,213,0,"*"],[408,1,2,224,0,"*"]],"groups":[{"title":"Optional VAE","bounding":[703,-458,445,183],"color":"#444","font_size":24},{"title":"ControlNet","bounding":[3857,422,1864,1366],"color":"#444","font_size":24}],"config":{},"extra":{},"version":0.4}