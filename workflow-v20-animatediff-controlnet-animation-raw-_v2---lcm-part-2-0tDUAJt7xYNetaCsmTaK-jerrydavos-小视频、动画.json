{"last_node_id":398,"last_link_id":761,"nodes":[{"id":176,"type":"Reroute","pos":[5420,970],"size":[90.4,26],"flags":{},"order":42,"mode":0,"inputs":[{"name":"","type":"*","link":688}],"outputs":[{"name":"LATENT","type":"LATENT","links":[367],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":361,"type":"CR Integer To String","pos":[5010,500],"size":{"0":315,"1":58},"flags":{"collapsed":true},"order":36,"mode":0,"inputs":[{"name":"int_","type":"INT","link":690,"widget":{"name":"int_"},"slot_index":0}],"outputs":[{"name":"STRING","type":"STRING","links":[689],"shape":3,"slot_index":0},{"name":"show_help","type":"STRING","links":null,"shape":3}],"properties":{"Node name for S&R":"CR Integer To String"},"widgets_values":[0]},{"id":151,"type":"EmptyLatentImage","pos":[4690,1040],"size":{"0":304,"1":112},"flags":{"collapsed":true},"order":33,"mode":0,"inputs":[{"name":"width","type":"INT","link":350,"widget":{"name":"width"}},{"name":"height","type":"INT","link":300,"widget":{"name":"height"}},{"name":"batch_size","type":"INT","link":305,"widget":{"name":"batch_size"},"slot_index":2}],"outputs":[{"name":"LATENT","type":"LATENT","links":[688],"shape":3,"slot_index":0}],"title":"Empty Latent Images","properties":{"Node name for S&R":"EmptyLatentImage"},"widgets_values":[504,888,10]},{"id":367,"type":"VHS_SplitImages","pos":[2290,850],"size":{"0":315,"1":118},"flags":{"collapsed":true},"order":43,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":697}],"outputs":[{"name":"IMAGE_A","type":"IMAGE","links":[698],"shape":3,"slot_index":0},{"name":"A_count","type":"INT","links":null,"shape":3},{"name":"IMAGE_B","type":"IMAGE","links":null,"shape":3},{"name":"B_count","type":"INT","links":null,"shape":3}],"title":".","properties":{"Node name for S&R":"VHS_SplitImages"},"widgets_values":{"split_index":5}},{"id":366,"type":"VHS_SplitImages","pos":[2280,360],"size":{"0":315,"1":118},"flags":{"collapsed":true},"order":44,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":699}],"outputs":[{"name":"IMAGE_A","type":"IMAGE","links":[700],"shape":3,"slot_index":0},{"name":"A_count","type":"INT","links":null,"shape":3},{"name":"IMAGE_B","type":"IMAGE","links":null,"shape":3},{"name":"B_count","type":"INT","links":null,"shape":3}],"title":".","properties":{"Node name for S&R":"VHS_SplitImages"},"widgets_values":{"split_index":5}},{"id":103,"type":"PreviewImage","pos":[2420,380],"size":{"0":210,"1":246},"flags":{},"order":49,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":700}],"properties":{"Node name for S&R":"PreviewImage"}},{"id":136,"type":"Reroute","pos":[6050,3110],"size":[75,26],"flags":{},"order":50,"mode":0,"inputs":[{"name":"","type":"*","link":703}],"outputs":[{"name":"VAE","type":"VAE","links":[677],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":213,"type":"Reroute","pos":[2520,3900],"size":[75,26],"flags":{},"order":46,"mode":0,"inputs":[{"name":"","type":"*","link":407}],"outputs":[{"name":"VAE","type":"VAE","links":[703],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":92,"type":"PreviewImage","pos":[2440,870],"size":{"0":210,"1":246},"flags":{},"order":48,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":698}],"properties":{"Node name for S&R":"PreviewImage"}},{"id":188,"type":"Reroute","pos":[2620,3600],"size":[75,26],"flags":{},"order":47,"mode":0,"inputs":[{"name":"","type":"*","link":456,"slot_index":0}],"outputs":[{"name":"CLIP","type":"CLIP","links":[721],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":226,"type":"CLIPSetLastLayer","pos":[4010,3060],"size":{"0":220,"1":60},"flags":{"collapsed":false},"order":53,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":670}],"outputs":[{"name":"CLIP","type":"CLIP","links":[724],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"CLIPSetLastLayer"},"widgets_values":[-24]},{"id":169,"type":"Reroute","pos":[4120,2890],"size":[82,26],"flags":{},"order":55,"mode":0,"inputs":[{"name":"","type":"*","link":729}],"outputs":[{"name":"MODEL","type":"MODEL","links":[722],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":165,"type":"Reroute","pos":[3670,2930],"size":[82,26],"flags":{},"order":54,"mode":0,"inputs":[{"name":"","type":"*","link":433,"slot_index":0}],"outputs":[{"name":"MODEL","type":"MODEL","links":[729],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":72,"type":"ControlNetApplyAdvanced","pos":[4720,2080],"size":{"0":320,"1":166},"flags":{},"order":62,"mode":0,"inputs":[{"name":"positive","type":"CONDITIONING","link":735},{"name":"negative","type":"CONDITIONING","link":733},{"name":"control_net","type":"CONTROL_NET","link":118},{"name":"image","type":"IMAGE","link":339}],"outputs":[{"name":"positive","type":"CONDITIONING","links":[218],"shape":3,"slot_index":0},{"name":"negative","type":"CONDITIONING","links":[219],"shape":3,"slot_index":1}],"properties":{"Node name for S&R":"ControlNetApplyAdvanced"},"widgets_values":[0.8,0,0.8],"color":"#2a363b","bgcolor":"#3f5159"},{"id":223,"type":"Reroute","pos":[2020,2170],"size":[75,26],"flags":{},"order":40,"mode":0,"inputs":[{"name":"","type":"*","link":748}],"outputs":[{"name":"CLIP","type":"CLIP","links":[456],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":391,"type":"FloatConstant","pos":[1160,1550],"size":{"0":210,"1":60},"flags":{},"order":0,"mode":0,"outputs":[{"name":"value","type":"FLOAT","links":[755],"shape":3,"slot_index":0}],"title":"LCM Lora Strength","properties":{"Node name for S&R":"FloatConstant"},"widgets_values":[0.65],"color":"#232","bgcolor":"#353"},{"id":373,"type":"LoraLoader","pos":[4550,2810],"size":{"0":320,"1":130},"flags":{"collapsed":true},"order":56,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":722},{"name":"clip","type":"CLIP","link":724},{"name":"strength_model","type":"FLOAT","link":756,"widget":{"name":"strength_model"},"slot_index":2}],"outputs":[{"name":"MODEL","type":"MODEL","links":[723],"shape":3,"slot_index":0},{"name":"CLIP","type":"CLIP","links":[725],"shape":3,"slot_index":1}],"properties":{"Node name for S&R":"LoraLoader"},"widgets_values":["lcm_pytorch_lora_weights.safetensors",0.65,0.1]},{"id":229,"type":"Text Multiline","pos":[1130,1830],"size":{"0":400,"1":208},"flags":{},"order":1,"mode":0,"outputs":[{"name":"STRING","type":"STRING","links":[414],"shape":3,"slot_index":0}],"title":"Negative","properties":{"Node name for S&R":"Text Multiline"},"widgets_values":["ugly, deformed, bad lighting, blurry, text, clouds, watermark, extra hands, bad quality, deformed hands, deformed fingers, nostalgic, drawing, painting, bad anatomy, worst quality, blurry, blurred, normal quality, bad focus, tripod, three legs, weird legs, short legs, bag, handbag, 3 hands, 4 hands, three hands\n\n(embedding:BadDream:1) boy, man, male,\n(embedding:ng_deepnegative_v1_75t:1), \n(embedding:epiCNegative:1), \n(embedding:bad-picture-chill-75v:1), \n(embedding:AS-YoungV2-neg:1), \n(embedding:ERA09NEGV2:1) "],"color":"#571a1a","bgcolor":"#6b2e2e"},{"id":104,"type":"PrimitiveNode","pos":[1130,540],"size":{"0":210,"1":80},"flags":{"collapsed":false},"order":2,"mode":0,"outputs":[{"name":"INT","type":"INT","links":[350],"slot_index":0,"widget":{"name":"width"}}],"title":"Width","properties":{"Run widget replace on values":false},"widgets_values":[504,"fixed"],"color":"#223","bgcolor":"#335"},{"id":105,"type":"PrimitiveNode","pos":[1130,670],"size":{"0":210,"1":80},"flags":{"collapsed":false},"order":3,"mode":0,"outputs":[{"name":"INT","type":"INT","links":[300],"slot_index":0,"widget":{"name":"height"}}],"title":"Height","properties":{"Run widget replace on values":false},"widgets_values":[888,"fixed"],"color":"#223","bgcolor":"#335"},{"id":164,"type":"PrimitiveNode","pos":[1130,880],"size":{"0":210,"1":80},"flags":{},"order":4,"mode":0,"outputs":[{"name":"INT","type":"INT","links":[361,362],"slot_index":0,"widget":{"name":"start_index"}}],"title":"Skip Frames","properties":{"Run widget replace on values":false},"widgets_values":[0,"fixed"],"color":"#232","bgcolor":"#353"},{"id":160,"type":"PrimitiveNode","pos":[1130,1160],"size":{"0":210,"1":80},"flags":{},"order":5,"mode":0,"outputs":[{"name":"INT","type":"INT","links":[305,359,360],"slot_index":0,"widget":{"name":"batch_size"}}],"title":"Batch Range","properties":{"Run widget replace on values":false},"widgets_values":[10,"fixed"],"color":"#232","bgcolor":"#353"},{"id":94,"type":"ADE_AnimateDiffUniformContextOptions","pos":[2600,3030],"size":{"0":315,"1":154},"flags":{"collapsed":true},"order":6,"mode":0,"outputs":[{"name":"CONTEXT_OPTIONS","type":"CONTEXT_OPTIONS","links":[206],"shape":3}],"properties":{"Node name for S&R":"ADE_AnimateDiffUniformContextOptions"},"widgets_values":[16,1,4,"uniform",true]},{"id":97,"type":"ControlNetLoaderAdvanced","pos":[2030,580],"size":{"0":352,"1":64},"flags":{},"order":7,"mode":0,"inputs":[{"name":"timestep_keyframe","type":"TIMESTEP_KEYFRAME","link":null}],"outputs":[{"name":"CONTROL_NET","type":"CONTROL_NET","links":[209],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"ControlNetLoaderAdvanced"},"widgets_values":["control_v11p_sd15_softedge.pth"],"color":"#232","bgcolor":"#353"},{"id":224,"type":"Reroute","pos":[1710,2270],"size":[75,26],"flags":{},"order":37,"mode":0,"inputs":[{"name":"","type":"*","link":758}],"outputs":[{"name":"VAE","type":"VAE","links":[407]}],"properties":{"showOutputText":true,"horizontal":false}},{"id":378,"type":"Reroute","pos":[2220,2090],"size":[75,26],"flags":{},"order":39,"mode":0,"inputs":[{"name":"","type":"*","link":747}],"outputs":[{"name":"","type":"MODEL","links":[740],"slot_index":0}],"properties":{"showOutputText":false,"horizontal":false}},{"id":319,"type":"PreviewImage","pos":[6860,1260],"size":{"0":210,"1":246},"flags":{"collapsed":false},"order":69,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":702}],"title":"Output Image","properties":{"Node name for S&R":"PreviewImage"}},{"id":7,"type":"KSampler","pos":[5850,1280],"size":{"0":320,"1":450},"flags":{"pinned":false},"order":64,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":398},{"name":"positive","type":"CONDITIONING","link":590,"slot_index":1},{"name":"negative","type":"CONDITIONING","link":591},{"name":"latent_image","type":"LATENT","link":367},{"name":"seed","type":"INT","link":6,"widget":{"name":"seed"}},{"name":"steps","type":"INT","link":751,"widget":{"name":"steps"},"slot_index":5},{"name":"cfg","type":"FLOAT","link":750,"widget":{"name":"cfg"},"slot_index":6}],"outputs":[{"name":"LATENT","type":"LATENT","links":[9],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"KSampler"},"widgets_values":[539728296665945,"fixed",8,4.5,"lcm","normal",1],"color":"#2a363b","bgcolor":"#3f5159"},{"id":369,"type":"ModelSamplingDiscrete","pos":[4860,2920],"size":{"0":315,"1":82},"flags":{"collapsed":true},"order":57,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":723}],"outputs":[{"name":"MODEL","type":"MODEL","links":[728],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"ModelSamplingDiscrete"},"widgets_values":["lcm",false]},{"id":170,"type":"Reroute","pos":[4230,2580],"size":[75,26],"flags":{},"order":58,"mode":0,"inputs":[{"name":"","type":"*","link":725}],"outputs":[{"name":"CLIP","type":"CLIP","links":[661,679],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":344,"type":"smZ CLIPTextEncode","pos":[3800,2280],"size":{"0":220,"1":160},"flags":{"collapsed":true},"order":60,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":661},{"name":"text","type":"STRING","link":659,"widget":{"name":"text"}}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[735],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"smZ CLIPTextEncode"},"widgets_values":["","comfy",true,true,false,false,6,1024,1024,0,0,1024,1024,"","",1],"color":"#232","bgcolor":"#353"},{"id":230,"type":"smZ CLIPTextEncode","pos":[3800,2320],"size":{"0":220,"1":160},"flags":{"collapsed":true},"order":61,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":679},{"name":"text","type":"STRING","link":414,"widget":{"name":"text"}}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","links":[733],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"smZ CLIPTextEncode"},"widgets_values":["","comfy",true,false,false,false,6,1024,1024,0,0,1024,1024,"","",1],"color":"#322","bgcolor":"#533"},{"id":392,"type":"Reroute","pos":[3370,2700],"size":[75,26],"flags":{},"order":32,"mode":0,"inputs":[{"name":"","type":"*","link":755,"widget":{"name":"value"}}],"outputs":[{"name":"","type":"FLOAT","links":[756],"slot_index":0}],"properties":{"showOutputText":false,"horizontal":false}},{"id":362,"type":"Int Literal","pos":[1130,1000],"size":{"0":210,"1":80},"flags":{},"order":8,"mode":0,"outputs":[{"name":"INT","type":"INT","links":[690],"shape":3}],"title":"Batch Number Naming","properties":{"Node name for S&R":"Int Literal"},"widgets_values":[1],"color":"#232","bgcolor":"#353"},{"id":205,"type":"Note","pos":[5320,2290],"size":{"0":320,"1":160},"flags":{},"order":9,"mode":0,"title":"Additional ControlNets","properties":{"text":""},"widgets_values":["You Can Add more ControlNets, just make that Pass in the ControlNet_Passes_Export.json and duplicating the directory node and using it like these previous nodes.\n\nMore control nets do not affect the time to render as they have already been rendered which makes it easy to test animations. By default 2 controlNets are enough. \n\n"],"color":"#432","bgcolor":"#653"},{"id":368,"type":"VHS_SplitImages","pos":[6870,1220],"size":{"0":315,"1":118},"flags":{"collapsed":true},"order":67,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":714}],"outputs":[{"name":"IMAGE_A","type":"IMAGE","links":[702],"shape":3,"slot_index":0},{"name":"A_count","type":"INT","links":null,"shape":3},{"name":"IMAGE_B","type":"IMAGE","links":null,"shape":3},{"name":"B_count","type":"INT","links":null,"shape":3}],"title":"Preview Only 5 Images","properties":{"Node name for S&R":"VHS_SplitImages"},"widgets_values":{"split_index":5}},{"id":353,"type":"Text String","pos":[6810,890],"size":{"0":315,"1":190},"flags":{"collapsed":true},"order":10,"mode":0,"inputs":[],"outputs":[{"name":"STRING","type":"STRING","links":[682],"shape":3,"slot_index":0},{"name":"STRING","type":"STRING","links":[],"shape":3,"slot_index":1},{"name":"STRING","type":"STRING","links":null,"shape":3},{"name":"STRING","type":"STRING","links":null,"shape":3}],"title":"Name","properties":{"Node name for S&R":"Text String"},"widgets_values":["Batch_","","",""]},{"id":354,"type":"Text Concatenate","pos":[6960,960],"size":{"0":315,"1":178},"flags":{"collapsed":true},"order":45,"mode":0,"inputs":[{"name":"text_a","type":"STRING","link":682,"widget":{"name":"text_a"}},{"name":"text_b","type":"STRING","link":689,"widget":{"name":"text_b"}},{"name":"text_c","type":"STRING","link":null,"widget":{"name":"text_c"}},{"name":"text_d","type":"STRING","link":null,"widget":{"name":"text_d"}}],"outputs":[{"name":"STRING","type":"STRING","links":[684],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"Text Concatenate"},"widgets_values":["","","false","","",""]},{"id":2,"type":"VAELoader","pos":[1130,2270],"size":{"0":320,"1":64},"flags":{},"order":11,"mode":0,"outputs":[{"name":"VAE","type":"VAE","links":[758],"shape":3,"slot_index":0}],"title":"Optional VAE","properties":{"Node name for S&R":"VAELoader"},"widgets_values":["vae-ft-mse-840000-ema-pruned.ckpt"]},{"id":393,"type":"CR LoRA Stack","pos":[790,2410],"size":{"0":315,"1":342},"flags":{"collapsed":false},"order":12,"mode":0,"inputs":[{"name":"lora_stack","type":"LORA_STACK","link":null}],"outputs":[{"name":"LORA_STACK","type":"LORA_STACK","links":[757],"shape":3,"slot_index":0},{"name":"show_help","type":"STRING","links":null,"shape":3}],"title":"[Optional] CR LoRA Stack","properties":{"Node name for S&R":"CR LoRA Stack"},"widgets_values":["On","None",1,1,"On","None",1,1,"On","None",1,1],"color":"#232","bgcolor":"#353"},{"id":1,"type":"CheckpointLoaderSimpleWithNoiseSelect","pos":[1130,2090],"size":{"0":310,"1":130},"flags":{},"order":13,"mode":0,"outputs":[{"name":"MODEL","type":"MODEL","links":[747],"shape":3,"slot_index":0},{"name":"CLIP","type":"CLIP","links":[748],"shape":3,"slot_index":1},{"name":"VAE","type":"VAE","links":[],"shape":3,"slot_index":2}],"title":"Load Checkpoint","properties":{"Node name for S&R":"CheckpointLoaderSimpleWithNoiseSelect"},"widgets_values":["imp_v10.safetensors","sqrt_linear (AnimateDiff)"],"color":"#232","bgcolor":"#353"},{"id":395,"type":"Note","pos":[450,1630],"size":{"0":520,"1":290},"flags":{},"order":14,"mode":0,"title":"Recommended Models and Loras","properties":{"text":""},"widgets_values":["------------------------------------------------------------\nModels - \n\n1) Epic Realism - https://civitai.com/models/25694?modelVersionId=143906\n*Epic Realism Natural RC1 Vae seems best for realistic Result.\n\n2) Imp Anime Model - https://civitai.com/models/56680/imp\n3) Dark Shushi - https://civitai.com/models/24779/dark-sushi-mix-mix\n4) Mistoon Collection - https://civitai.com/user/Inzaniak/models\n5) MeinaMix - https://civitai.com/models/7240/meinamix\n6) Animerge - https://civitai.com/models/144249?modelVersionId=224851\n\n-----------------------------------------------------------\n\nLoras - \n\n1) Skin Tone Slider - https://civitai.com/models/112594/skin-tone-slider-lora\nUse Negative Values (-1) for better result. \n\n2)  Saturation Tweaker - https://civitai.com/models/71192/saturation-tweaker-lora-lora\nAdd Saturation ( 0.3- 0.7) when getting less contrast. \n\n3) Detail Slider  -  \nhttps://civitai.com/models/58390/detail-tweaker-lora-lora \nhttps://civitai.com/models/153562/detail-slider-lora\nUse Negative Values if getting weird details in High CFG value\n\n4) Blue theme- https://civitai.com/models/102153/blue-theme\nUse Loras like this which control background to get more better backgrounds.\n"],"color":"#1828a6","bgcolor":"#2c3cba"},{"id":70,"type":"ControlNetLoaderAdvanced","pos":[2050,1080],"size":{"0":352,"1":64},"flags":{"collapsed":false},"order":15,"mode":0,"inputs":[{"name":"timestep_keyframe","type":"TIMESTEP_KEYFRAME","link":null}],"outputs":[{"name":"CONTROL_NET","type":"CONTROL_NET","links":[118],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"ControlNetLoaderAdvanced"},"widgets_values":["control_v11p_sd15_openpose.pth"],"color":"#232","bgcolor":"#353"},{"id":172,"type":"LoadImagesFromDirectory","pos":[2040,880],"size":{"0":315,"1":146},"flags":{},"order":34,"mode":0,"inputs":[{"name":"image_load_cap","type":"INT","link":359,"widget":{"name":"image_load_cap"},"slot_index":0},{"name":"start_index","type":"INT","link":361,"widget":{"name":"start_index"}}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[339,697],"shape":3,"slot_index":0},{"name":"MASK","type":"MASK","links":null,"shape":3},{"name":"INT","type":"INT","links":null,"shape":3}],"title":"ControlNet 1","properties":{"Node name for S&R":"LoadImagesFromDirectory"},"widgets_values":["F:\\#Projects\\1) SD Animation\\16) Loka Loka LCM\\Passes\\OP",10,0],"color":"#323","bgcolor":"#535"},{"id":174,"type":"LoadImagesFromDirectory","pos":[2030,390],"size":{"0":315,"1":146},"flags":{},"order":35,"mode":0,"inputs":[{"name":"image_load_cap","type":"INT","link":360,"widget":{"name":"image_load_cap"},"slot_index":0},{"name":"start_index","type":"INT","link":362,"widget":{"name":"start_index"}}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[345,699],"shape":3,"slot_index":0},{"name":"MASK","type":"MASK","links":null,"shape":3},{"name":"INT","type":"INT","links":null,"shape":3}],"title":"ControlNet 2","properties":{"Node name for S&R":"LoadImagesFromDirectory"},"widgets_values":["F:\\#Projects\\1) SD Animation\\16) Loka Loka LCM\\Passes\\HED_Fixed",10,0],"color":"#323","bgcolor":"#535"},{"id":5,"type":"PrimitiveNode","pos":[1130,410],"size":{"0":210,"1":80},"flags":{},"order":16,"mode":0,"outputs":[{"name":"INT","type":"INT","links":[6],"slot_index":0,"widget":{"name":"seed"}}],"title":"Seed","properties":{"Run widget replace on values":false},"widgets_values":[539728296665945,"randomize"],"color":"#171717","bgcolor":"#2b2b2b"},{"id":93,"type":"ADE_AnimateDiffLoaderWithContext","pos":[3060,2810],"size":{"0":407.929931640625,"1":190},"flags":{"collapsed":false},"order":52,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":669},{"name":"context_options","type":"CONTEXT_OPTIONS","link":206,"slot_index":1},{"name":"motion_lora","type":"MOTION_LORA","link":null},{"name":"motion_model_settings","type":"MOTION_MODEL_SETTINGS","link":null}],"outputs":[{"name":"MODEL","type":"MODEL","links":[433],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"ADE_AnimateDiffLoaderWithContext"},"widgets_values":["motionModel_v01.ckpt","sqrt_linear (AnimateDiff)",1,false]},{"id":383,"type":"Int Literal","pos":[1160,1350],"size":{"0":210,"1":60},"flags":{},"order":17,"mode":0,"outputs":[{"name":"INT","type":"INT","links":[751],"shape":3}],"title":"Sampler Steps","properties":{"Node name for S&R":"Int Literal"},"widgets_values":[8],"color":"#232","bgcolor":"#353"},{"id":346,"type":"CR LoRA Stack","pos":[1130,2410],"size":{"0":315,"1":342},"flags":{"collapsed":false},"order":38,"mode":0,"inputs":[{"name":"lora_stack","type":"LORA_STACK","link":757}],"outputs":[{"name":"LORA_STACK","type":"LORA_STACK","links":[667],"shape":3,"slot_index":0},{"name":"show_help","type":"STRING","links":null,"shape":3}],"title":"[Optional] CR LoRA Stack","properties":{"Node name for S&R":"CR LoRA Stack"},"widgets_values":["On","None",1,1,"On","None",1,1,"On","None",1,1],"color":"#232","bgcolor":"#353"},{"id":384,"type":"Note","pos":[450,1340],"size":{"0":520,"1":230},"flags":{},"order":18,"mode":0,"title":"LCM Sampler Step and CFG","properties":{"text":""},"widgets_values":["Sampler Steps - Use Steps between 6-12 \n\nSampler CFG - Use Between 1-5 , Higher values causes artifacts, color noise, and weird backgrounds.\n\nLCM Lora Strength - 0.65 seems good, you can experiment with higher values, also balance CFG and steps.\n\n-------------------------------\n\n*Background still gets messy, use low cfg for good background\n\n*Value of cfg below 4 causes some faded look. You can experiment with \n1) LCM Lora Strength \n2) Sampler Steps\n3) Sampler CFG \n\nAll three are dependent on each other.\n\n*DreamShaper 8 SD 1.5 LCM model produces bad result, feel free to try and experiment.\n\n\n\n"],"color":"#008f74","bgcolor":"#00a388"},{"id":99,"type":"ControlNetApplyAdvanced","pos":[5320,2080],"size":{"0":320,"1":166},"flags":{},"order":63,"mode":0,"inputs":[{"name":"positive","type":"CONDITIONING","link":218},{"name":"negative","type":"CONDITIONING","link":219},{"name":"control_net","type":"CONTROL_NET","link":209},{"name":"image","type":"IMAGE","link":345}],"outputs":[{"name":"positive","type":"CONDITIONING","links":[590],"shape":3,"slot_index":0},{"name":"negative","type":"CONDITIONING","links":[591],"shape":3,"slot_index":1}],"properties":{"Node name for S&R":"ControlNetApplyAdvanced"},"widgets_values":[0.45,0.1,0.4],"color":"#2a363b","bgcolor":"#3f5159"},{"id":204,"type":"Note","pos":[4720,2290],"size":{"0":320,"1":140},"flags":{},"order":19,"mode":0,"title":"Softedge, Canny, Lineart","properties":{"text":""},"widgets_values":["Stronger Strength and End Percent results in floating artifacts and Alien objects in Softedge, Canny, or lineArt Models\n\nYou can experiment with depth also.\n"],"color":"#432","bgcolor":"#653"},{"id":201,"type":"Note","pos":[440,1980],"size":{"0":530,"1":210},"flags":{},"order":20,"mode":0,"title":"Prompt Note","properties":{"text":""},"widgets_values":["*Positive Prompt: Write as usual, specify minute details, the elements are usually changed during the render, also you can try to use same keywords multiple times but same meaning ( Eg: blue jeans, blue color jeans, jeans of blue color) to reduce major changes. \n\nUsing the word multiple times increase it's strength.\nAvoid writing multiple color words. A prompt which has \"black\" keyword written x3 will darken the image x3\n\n\nIf you weight the keywords like \"(this:1.9), it may produce glitchy result. Avoid high weights.\n\n*Negative Prompt: Write as usual, Sometimes Negative prompts causes noise in images, try reducing the use of embeddings if you encounter them. \n\n"],"color":"#432","bgcolor":"#653"},{"id":189,"type":"Note","pos":[100,1980],"size":{"0":320,"1":210},"flags":{},"order":21,"mode":0,"title":"CheckPoint","properties":{"text":""},"widgets_values":["Checkpoint - Try Different Checkpoints for creative (results:0.95) \n\n\nTo use Lora - add the Lora in the loras stack\n\nIf your renders are glitchy or incomplete, it may be lora incompatible with AnimateDiff Loader or You have some problem in the Prompts.\n\nBeta_Scheldule: It only works with sqrt_linear(AnimateDiff)\n\n"],"color":"#432","bgcolor":"#653"},{"id":175,"type":"Note","pos":[440,1020],"size":{"0":530,"1":250},"flags":{},"order":22,"mode":0,"title":"Batch Range Note","properties":{"text":""},"widgets_values":["LCM - As lcm uses under 10 steps, you 2x input the batch range and image resolution. \n\nBatch Range - How much images you want to render in a single queue.\n\nIt also Controls the number of empty latent images for Ksampler\n\nUse Exact Number of images you want to render.\n\nDon't Use \"0\" as it also provides for Latent Image for ksampler else it will break.\n\nTIP: Use at least 10 frames for testing else it will give you noisy image.\n\n\n---------------------- \n\nBUG: If you are rendering images in batches because of low specs, After each Batch the Images will change even after same seed, so it can't be helped. \n\nSOLUTION: Render it in one go or longer batches, it will take hours to render, put some ice on the graphic card for faster result :D ( You can minimize this bug by specifying the minute details in prompts) or \nFix in Davinci Deflicker - Flora Light (Masking the duration only of the sudden change), \nAlso See the tip in Note Near the Ksampler node.\n\n--------------------\n\nBUG 2: I have 8GB graphics so max frames I can render in a single go is around 150 \n\nIf I go beyond that, the ksampler will show like its rendering but will not actually render.\n\nIf your GPU is not melting then your ksampler is stuck, try reducing the batch range then try melting again :)"],"color":"#432","bgcolor":"#653"},{"id":177,"type":"Note","pos":[440,740],"size":{"0":530,"1":220},"flags":{},"order":23,"mode":0,"title":"Skip Frames Note","properties":{"text":""},"widgets_values":["Skip Frames - After Each Queue, skip the \"total\" of rendered frames. \n(Give some rest to the computer so it does not catch fire, don't be cruel)\n\nEg:\n \n1st Queue- Batch Range 60 | Skip Frames 0  | Rendered 60 \n2nd Queue- Batch Range 60 | Skip Frames 60 | Rendered 60\n3rd Queue- Batch Range 60 | Skip Frames 120 (60+60)...\nand so on... till your batch size.\n\nInput your last batch correctly. \n\nWarning: Ksampler can stuck if your input batch range is greater than the source images.\n\nEg : I have my last batch of 55 images left but I input 60 images in batch range then the ksampler got stuck. \nThen I put 55 as my batch range then it worked. Hurraah!\n\n\n\nTip: In the input box, basic Maths can be done inside comfyui only not need of calculator. \n\nEg : if I put \"200-50\" (250 minus 50) in the input, it will calculate to 150 automatically, like wise other basic Maths\n\n\n\n\n\n\n\n"],"color":"#432","bgcolor":"#653"},{"id":225,"type":"Note","pos":[-810,280],"size":{"0":565.9544677734375,"1":719.0118408203125},"flags":{},"order":24,"mode":0,"title":"4) Bug List","properties":{"text":""},"widgets_values":["1) Out of Memory error, after reaching the Ksampler node\nCause: Your PC is Running out of Vram of the Graphic Card. \n◉ Solution:\nA) Just Queue Prompt again, sometimes it fixes the error, because it has already cached through the model loaders. (If you have an 8gb graphic card)  \nB) Batch Range is too high, try lowering it (150-200 in one batch should be fine)\nC) Resolution is too high, you can upscale later also... (use lower than 1000x1000)  \nD) The SD model you are using is very big in size, it takes up ram. Use different SD model. \nE) This workflow is not tested on SDXL models because of it's vram consumption, So avoid SDXLs.\n\n2) Rendered output frames are smudgy or incomplete. \nCause: Experimental Technology. Sometimes it works, sometimes don't.  \n◉ Solution: \nA) Try lowering the batch size, the details get smushed along the frames. Lower batch range (20-50) has the highest details. \nB) Your Prompt has weightings like -->(this:1.7)<-- remove this weighting. \nC) Negative Embeddings sometimes messes things up. Try isolating them one by one.   \n\n  \n\n4) Ksampler is stuck, it's rendering but not progressing. \n◉ Solution: \nA) If you do not hear the Phooooo... or Pheeeeee sound of the graphic card in a minute after when the green box hits the Ksampler node, that means it's stuck. You need to low down the batch range. It's too much to handle at once, so it handles none. Lower the batch range size.\n\nB) You have 40 images left in the last batch but the batch range is set to 50. So 50-40 is 10. This extra 10 images can stuck the KSampler.\n\nC) The Images leaks into CPU memory and render the extra images with CPU taking longer time.\nGo into Task Manager > Performance > GPU and see the \"Shared GPU memory\" If it's greater than 0.1 then the images are leaking into CPU, CPU can handle well upto 1GB of Shared GPU, greater than that it's super slow to render. \n\n5) I rendered out fine, but it's not looking what it should be\n◉ Solution: \nA) You might have mixed the passes in the control net unit. Check if Openpose passes are going in the openposemodel model. And like wise for the softedge, canny... and others.\nB) Try changing Lora and models, also prompts can affect upto a great extent. \n\n6) I have the same Seed but the transition images of the batches are not same and creates a sharp change.\n◉ Solution: Well the v2 version of this workflow includes IP adaptor and IP2P controlnet, by which it should be minimized, \nBTW this sharp change will not be noticeable after the Refiner Pass\n\n\n\n\n\n  \n"],"color":"#323","bgcolor":"#535","shape":2},{"id":10,"type":"VAEDecode","pos":[6410,1410],"size":{"0":210,"1":46},"flags":{"collapsed":true},"order":65,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":9},{"name":"vae","type":"VAE","link":677}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[713],"shape":3,"slot_index":0}],"properties":{"Node name for S&R":"VAEDecode"}},{"id":396,"type":"Note","pos":[5020,1850],"size":{"0":320,"1":176},"flags":{},"order":25,"mode":0,"title":"ControlNet Important Note","properties":{"text":""},"widgets_values":["* Lower Strength and End Percent can lead to creative results which will reduce the original image look (Applicable in Softedge, Canny, Depth, and LineArt Pass)\n\n* Greater Start percent around 0.3-0.5 tends to create a still image from the main prompt first and then an artifact character overlayed on it.  This Can be used for Abstract creation.\n\n"],"color":"#822bda","bgcolor":"#963fee"},{"id":382,"type":"Cfg Literal","pos":[1160,1450],"size":{"0":210,"1":60},"flags":{},"order":26,"mode":0,"outputs":[{"name":"FLOAT","type":"FLOAT","links":[750],"shape":3}],"title":"Sampler CFG","properties":{"Node name for S&R":"Cfg Literal"},"widgets_values":[2.5],"color":"#232","bgcolor":"#353"},{"id":334,"type":"Image Save","pos":[7340,890],"size":{"0":320,"1":560},"flags":{},"order":68,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":715},{"name":"output_path","type":"STRING","link":692,"widget":{"name":"output_path"}},{"name":"filename_prefix","type":"STRING","link":684,"widget":{"name":"filename_prefix"}}],"properties":{"Node name for S&R":"Image Save"},"widgets_values":["F:\\#Projects\\1) SD Animation\\14) Golden Dress\\Raw","","_",4,"false","png",100,"false","false","false","true","true","true"]},{"id":190,"type":"Note","pos":[-200,270],"size":{"0":565.9544677734375,"1":719.0118408203125},"flags":{},"order":27,"mode":0,"title":"Author's Note","properties":{"text":""},"widgets_values":["1) All Green Nodes are Inputs and require your attention, Purple Nodes are Input Images Directory Nodes for controlNet passes, and are very important else this workflow won't run. Neon Colors are Important notes.  \n\n\n\n2) Control Net Passes are already rendered to save time, you need to have them before using this workflow, Extract them using the Provided ControlNet_Passes_Export.json v2 file  (You can experiment with different control nets or use only one)\n\n3) If Faces are not Looking good, it's fine, the refiner pass will take care of it, else you can also try the Reactor Batch Face Swap or A1111 Method (Reactor can also swap bad faces with good one) \n\n4) Use value at least \"10\" in batch range to test render out your animation before final render. Lower than 10 frames may result in noisy images.\n\n\n5) Use Link Render Mode to straight lines in ComfyUI Settings (Gear Icon in the right of the Queues Box) so the workflow doesn't look like spaghetti. \n\n\n◉ FULL VIDEO TUTORIAL LINK of V1 here : https://youtu.be/HbfDjAMFi6w \nVersion 2 Tutorial will be out soon check this for updates : https://www.youtube.com/@Ai_Davos/videos \n\nWorkflows Download Folder Link : https://drive.google.com/drive/folders/1HoZxKUX7WAg7ObqP00R4oIv48sXCEryQ?usp=sharing\n\n\nI post my workflows, tutorials and secret techniques without any cost on my Patreon, just click \"join for free\" and sign up click \"skip the payment\" and you will be part of my journey for free.\nPatreon link: patreon.com/jerrydavos\n\n\nif you want to share your artwork with me, feel free to contact me on Discord - ID: jerrydavos \nor gmail : davos.jerry+contactai@gmail.com \nI will be very happy to see your works <3 \n\n\n\n-----------------------------------------------------------------\n\nINSTALLATION: \n\n \n*LCM LORA : https://civitai.com/models/195519?modelVersionId=225222\n\nIn ComfyUI Manager > click Install Missing Nodes.\n\nhttps://github.com/WASasquatch/was-node-suite-comfyui\nhttps://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes\nhttps://github.com/shiimizu/ComfyUI_smZNodes\nhttps://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet\nhttps://github.com/Kosinkadink/ComfyUI-AnimateDiff-Evolved\nhttps://github.com/Kosinkadink/ComfyUI-VideoHelperSuite\nhttps://github.com/giriss/comfy-image-saver\nhttps://github.com/kijai/ComfyUI-KJNodes\nhttps://github.com/YMC-GitHub/ymc-node-suite-comfyui\nhttps://github.com/Stability-AI/stability-ComfyUI-nodes\nhttps://github.com/pythongosssss/ComfyUI-Custom-Scripts\nhttps://github.com/LucianoCirino/efficiency-nodes-comfyui\nhttps://github.com/wolfden/ComfyUi_String_Function_Tree\nhttps://github.com/Stability-AI/stability-ComfyUI-nodes\nhttps://github.com/AlekPet/ComfyUI_Custom_Nodes_AlekPet\nhttps://github.com/FizzleDorf/ComfyUI_FizzNodes\nhttps://github.com/mcmonkeyprojects/sd-dynamic-thresholding\nhttps://github.com/giriss/comfy-image-saver\n\nAlso update all the nodes, if you have already installed previously, especially Animatediff Evolved for LCM to work Properly.\n\n-------------AnimateDIff Checkpoints-----------\n\nGo to Manager > Install Models and search for them.\n\n1) Temporaldiff-v1-animatediff - https://huggingface.co/CiaraRowles/TemporalDiff/tree/main\n2) motionModel_v01 - https://civitai.com/models/139237?modelVersionId=154097\n\nPut in  ComfyUI\\custom_nodes\\ComfyUI-AnimateDiff-Evolved\\models\n\n------------------------------------------------------------\n\n*Minimum Requirement to run AnimateDiff is Nvidia RTX cards with at least 8GB.\n\nNode Workflow by\nJerry Davos\n"],"color":"#2a363b","bgcolor":"#3f5159","shape":4},{"id":347,"type":"CR Apply LoRA Stack","pos":[2760,3290],"size":{"0":210,"1":66},"flags":{"collapsed":true},"order":51,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":740},{"name":"clip","type":"CLIP","link":721},{"name":"lora_stack","type":"LORA_STACK","link":667}],"outputs":[{"name":"MODEL","type":"MODEL","links":[669],"shape":3,"slot_index":0},{"name":"CLIP","type":"CLIP","links":[670],"shape":3,"slot_index":1},{"name":"show_help","type":"STRING","links":null,"shape":3}],"properties":{"Node name for S&R":"CR Apply LoRA Stack"}},{"id":356,"type":"Note","pos":[3080,3050],"size":{"0":370,"1":120},"flags":{},"order":28,"mode":0,"title":"AnimateDiff","properties":{"text":""},"widgets_values":["Model - motionModel_v01 and Temporaldiff-v1-animatediff was seen to produce best results.\nContext Length to 16\n----------------------------\nmotionModel_v01 - https://civitai.com/models/139237?modelVersionId=154097\n\nTemporaldiff - https://huggingface.co/CiaraRowles/TemporalDiff/tree/main\n* Temporal Diff can sometime give yellow tint to the final image, which can be fixed in post using curves>playing with the blue channel.\n\n\nFeel free to test out other motion models. \n"],"color":"#432","bgcolor":"#653"},{"id":345,"type":"Text Multiline","pos":[1130,1680],"size":{"0":398.4864501953125,"1":110.9655990600586},"flags":{},"order":29,"mode":0,"outputs":[{"name":"STRING","type":"STRING","links":[659],"shape":3,"slot_index":0}],"title":"Positive","properties":{"Node name for S&R":"Text Multiline"},"widgets_values":["masterpiece, beautiful, aesthetic"],"color":"#1a571a","bgcolor":"#2e6b2e"},{"id":208,"type":"Note","pos":[420,270],"size":{"0":557.23828125,"1":363.5209045410156},"flags":{},"order":30,"mode":0,"title":"#2 Animation Raw - LCM","properties":{"text":""},"widgets_values":["HOW TO USE: \n\n1) Choose Model checkpoint you want to use\n2) Enter Width and Height of your Output Image \n3) Choose Positive Prompts you want to see in the output\n4) Choose Loras, (You have to experiment which looks good or not)\n5) Paste the Passes Directories in ControlNets (1 and 2) Loaders and set their models and weight (See Neon Purple note)\n6) Paste The Directory where you want to save the Images in the Output Save Directory Node\n7) Select Batch Range (Number of images you want to render in one Queue)\n8) Choose LCM Settings, Default is good but experimental (See note)\n9) After every batch you can increase the batch naming for organizing the batches.\n10) After every queue increase the skip frames to the Total number of images rendered already.\n11) After All the batches are rendered it's Ready for #3 LCM Refiner workflow\n\n*Don't Use Overlapping Technique in this phase, Use that in the final refiner phase, \n________________________________________\n\nMain Download Folder Link : https://drive.google.com/drive/folders/1HoZxKUX7WAg7ObqP00R4oIv48sXCEryQ?usp=sharing\n_________________________________________\n\nUpdate Log: Version 2 - Dec 23 \n\n1) The weird color bleed/tint in the final images is removed by LCM technique (Found Experimentally) in this workflow. \n\n*A yellow tint may be observed (In low cfg) with TemporalDiff model in the final output which can be removed easily in post processing by using curves > blue channel >playing with the curve.   \n\n2) LCM now supported, will have 2x - 3x Render speed with higher batch range input, as lcm uses under 10 steps, you 2x input the batch range and image resolution. \n\n3) Added Batch Number Naming for organizing\n4) Added Output Save Location Path\n5) Added bunch of custom nodes for more efficiency and organizing. (See installation List)\n\n________________________________________\n\n\n\n* If Faces are not Looking good, or some weird but small artifacts, it's fine, the refiner pass will take care of it\n* In prompts experiment with extreme words, and also test with loras with low strength. \n* Background still has weird artifacts. Play with sampler cfg (1-6) to see some change.\n* IP adaptor produces messy results with LCM"],"color":"#934000","bgcolor":"#a75406","shape":4},{"id":217,"type":"Reroute","pos":[5550,2890],"size":[82,26],"flags":{},"order":59,"mode":0,"inputs":[{"name":"","type":"*","link":728}],"outputs":[{"name":"MODEL","type":"MODEL","links":[398],"slot_index":0}],"properties":{"showOutputText":true,"horizontal":false}},{"id":370,"type":"Reroute","pos":[6670,1140],"size":[75,26],"flags":{},"order":66,"mode":0,"inputs":[{"name":"","type":"*","link":713}],"outputs":[{"name":"","type":"IMAGE","links":[714,715],"slot_index":0}],"properties":{"showOutputText":false,"horizontal":false}},{"id":363,"type":"Reroute","pos":[5010,420],"size":[75,26],"flags":{},"order":41,"mode":0,"inputs":[{"name":"","type":"*","link":761,"widget":{"name":"value"}}],"outputs":[{"name":"","type":"STRING","links":[692],"slot_index":0}],"properties":{"showOutputText":false,"horizontal":false}},{"id":398,"type":"String to Text","pos":[1130,300],"size":{"0":320,"1":60},"flags":{},"order":31,"mode":0,"outputs":[{"name":"STRING","type":"STRING","links":[761],"shape":3,"slot_index":0}],"title":"Output Folder Path","properties":{"Node name for S&R":"String to Text"},"widgets_values":["F:\\#Projects\\1) SD Animation\\17) Queencard\\Face_Fix"],"color":"#323","bgcolor":"#535"}],"links":[[6,5,0,7,4,"INT"],[9,7,0,10,0,"LATENT"],[118,70,0,72,2,"CONTROL_NET"],[206,94,0,93,1,"CONTEXT_OPTIONS"],[209,97,0,99,2,"CONTROL_NET"],[218,72,0,99,0,"CONDITIONING"],[219,72,1,99,1,"CONDITIONING"],[300,105,0,151,1,"INT"],[305,160,0,151,2,"INT"],[339,172,0,72,3,"IMAGE"],[345,174,0,99,3,"IMAGE"],[350,104,0,151,0,"INT"],[359,160,0,172,0,"INT"],[360,160,0,174,0,"INT"],[361,164,0,172,1,"INT"],[362,164,0,174,1,"INT"],[367,176,0,7,3,"LATENT"],[398,217,0,7,0,"MODEL"],[407,224,0,213,0,"*"],[414,229,0,230,1,"STRING"],[433,93,0,165,0,"*"],[456,223,0,188,0,"*"],[590,99,0,7,1,"CONDITIONING"],[591,99,1,7,2,"CONDITIONING"],[659,345,0,344,1,"STRING"],[661,170,0,344,0,"CLIP"],[667,346,0,347,2,"LORA_STACK"],[669,347,0,93,0,"MODEL"],[670,347,1,226,0,"CLIP"],[677,136,0,10,1,"VAE"],[679,170,0,230,0,"CLIP"],[682,353,0,354,0,"STRING"],[684,354,0,334,2,"STRING"],[688,151,0,176,0,"*"],[689,361,0,354,1,"STRING"],[690,362,0,361,0,"INT"],[692,363,0,334,1,"STRING"],[697,172,0,367,0,"IMAGE"],[698,367,0,92,0,"IMAGE"],[699,174,0,366,0,"IMAGE"],[700,366,0,103,0,"IMAGE"],[702,368,0,319,0,"IMAGE"],[703,213,0,136,0,"*"],[713,10,0,370,0,"*"],[714,370,0,368,0,"IMAGE"],[715,370,0,334,0,"IMAGE"],[721,188,0,347,1,"CLIP"],[722,169,0,373,0,"MODEL"],[723,373,0,369,0,"MODEL"],[724,226,0,373,1,"CLIP"],[725,373,1,170,0,"*"],[728,369,0,217,0,"*"],[729,165,0,169,0,"*"],[733,230,0,72,1,"CONDITIONING"],[735,344,0,72,0,"CONDITIONING"],[740,378,0,347,0,"MODEL"],[747,1,0,378,0,"*"],[748,1,1,223,0,"*"],[750,382,0,7,6,"FLOAT"],[751,383,0,7,5,"INT"],[755,391,0,392,0,"*"],[756,392,0,373,2,"FLOAT"],[757,393,0,346,0,"LORA_STACK"],[758,2,0,224,0,"*"],[761,398,0,363,0,"*"]],"groups":[],"config":{},"extra":{},"version":0.4}